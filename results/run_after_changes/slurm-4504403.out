This job can be monitored from: https://job.c3se.chalmers.se/alvis/4504403
We are in main.
Warning: Folder for participant sub-OAS30937 does not exist and will be deleted.
Warning: Folder for participant sub-OAS31357 does not exist and will be deleted.
Train size (number of participants): 328, Validation size: 109, Test size: 110
We are in train.
Using device: cuda
Last block has number of input channels: 64
Last block has number of output channels: 16
Warning: No matching T1w image found for sub-OAS30369 in session(s). Skipping.
Warning: No matching T1w image found for sub-OAS30369 in session(s). Skipping.
Warning: No matching T1w image found for sub-OAS30369 in session(s). Skipping.
Warning: No matching T1w image found for sub-OAS30369 in session(s). Skipping.
Warning: No matching T1w image found for sub-OAS30369 in session(s). Skipping.
Warning: No matching T1w image found for sub-OAS30369 in session(s). Skipping.
Warning: No matching T1w image found for sub-OAS30137 in session(s). Skipping.
Warning: No matching T1w image found for sub-OAS30137 in session(s). Skipping.
Warning: No matching T1w image found for sub-OAS30659 in session(s). Skipping.
Warning: No matching T1w image found for sub-OAS30659 in session(s). Skipping.
Loaded 1451 image pairs.
Loaded 1451 rows of metadata.
Loaded 1451 targets.
Loaded 448 image pairs.
Loaded 448 rows of metadata.
Loaded 448 targets.
We are in epoch (training):  0
/mimer/NOBACKUP/groups/brainage/thesis_brainage/my_venv/lib/python3.12/site-packages/torchio/data/image.py:248: UserWarning: Using TorchIO images without a torchio.SubjectsLoader in PyTorch >= 2.3 might have unexpected consequences, e.g., the collated batches will be instances of torchio.Subject with 5D images. Replace your PyTorch DataLoader with a torchio.SubjectsLoader so that the collated batch becomes a dictionary, as expected. See https://github.com/TorchIO-project/torchio/issues/1179 for more context about this issue.
  warnings.warn(message, stacklevel=1)
Epoch 0: Avg Train Loss = 10.7658
Epoch 0: Avg Train MAE = 2.4586
We are in epoch (val):  0
Epoch 0: Avg Val Loss = 4.0566
Epoch 0: Avg Val MAE = 1.5701
Validation loss improved, saving best model.
We are in epoch (training):  1
Epoch 1: Avg Train Loss = 4.6066
Epoch 1: Avg Train MAE = 1.6858
We are in epoch (val):  1
Epoch 1: Avg Val Loss = 3.5312
Epoch 1: Avg Val MAE = 1.4814
Validation loss improved, saving best model.
We are in epoch (training):  2
Epoch 2: Avg Train Loss = 3.8465
Epoch 2: Avg Train MAE = 1.5535
We are in epoch (val):  2
Epoch 2: Avg Val Loss = 3.3555
Epoch 2: Avg Val MAE = 1.4211
Validation loss improved, saving best model.
We are in epoch (training):  3
Epoch 3: Avg Train Loss = 3.4687
Epoch 3: Avg Train MAE = 1.4539
We are in epoch (val):  3
Epoch 3: Avg Val Loss = 2.8258
Epoch 3: Avg Val MAE = 1.3025
Validation loss improved, saving best model.
We are in epoch (training):  4
Epoch 4: Avg Train Loss = 3.3987
Epoch 4: Avg Train MAE = 1.4278
We are in epoch (val):  4
Epoch 4: Avg Val Loss = 3.6180
Epoch 4: Avg Val MAE = 1.4064
No improvement in validation loss for 1 epochs.
We are in epoch (training):  5
Epoch 5: Avg Train Loss = 3.2459
Epoch 5: Avg Train MAE = 1.3870
We are in epoch (val):  5
Epoch 5: Avg Val Loss = 2.8907
Epoch 5: Avg Val MAE = 1.3150
No improvement in validation loss for 2 epochs.
We are in epoch (training):  6
Epoch 6: Avg Train Loss = 3.4547
Epoch 6: Avg Train MAE = 1.4366
We are in epoch (val):  6
Epoch 6: Avg Val Loss = 2.8116
Epoch 6: Avg Val MAE = 1.2923
Validation loss improved, saving best model.
We are in epoch (training):  7
Epoch 7: Avg Train Loss = 2.8515
Epoch 7: Avg Train MAE = 1.3052
We are in epoch (val):  7
Epoch 7: Avg Val Loss = 2.7508
Epoch 7: Avg Val MAE = 1.2504
Validation loss improved, saving best model.
We are in epoch (training):  8
Epoch 8: Avg Train Loss = 2.5385
Epoch 8: Avg Train MAE = 1.2417
We are in epoch (val):  8
Epoch 8: Avg Val Loss = 2.6323
Epoch 8: Avg Val MAE = 1.2084
Validation loss improved, saving best model.
We are in epoch (training):  9
Epoch 9: Avg Train Loss = 2.5163
Epoch 9: Avg Train MAE = 1.2367
We are in epoch (val):  9
Epoch 9: Avg Val Loss = 2.4953
Epoch 9: Avg Val MAE = 1.1811
Validation loss improved, saving best model.
We are in epoch (training):  10
Epoch 10: Avg Train Loss = 2.2355
Epoch 10: Avg Train MAE = 1.1646
We are in epoch (val):  10
Epoch 10: Avg Val Loss = 2.5392
Epoch 10: Avg Val MAE = 1.2042
No improvement in validation loss for 1 epochs.
We are in epoch (training):  11
Epoch 11: Avg Train Loss = 2.1523
Epoch 11: Avg Train MAE = 1.1489
We are in epoch (val):  11
Epoch 11: Avg Val Loss = 2.8095
Epoch 11: Avg Val MAE = 1.2405
No improvement in validation loss for 2 epochs.
We are in epoch (training):  12
Epoch 12: Avg Train Loss = 2.2004
Epoch 12: Avg Train MAE = 1.1589
We are in epoch (val):  12
Epoch 12: Avg Val Loss = 2.6385
Epoch 12: Avg Val MAE = 1.1857
No improvement in validation loss for 3 epochs.
We are in epoch (training):  13
Epoch 13: Avg Train Loss = 2.3047
Epoch 13: Avg Train MAE = 1.1567
We are in epoch (val):  13
Epoch 13: Avg Val Loss = 2.5872
Epoch 13: Avg Val MAE = 1.1744
No improvement in validation loss for 4 epochs.
We are in epoch (training):  14
Epoch 14: Avg Train Loss = 2.3282
Epoch 14: Avg Train MAE = 1.1449
We are in epoch (val):  14
Epoch 14: Avg Val Loss = 2.8699
Epoch 14: Avg Val MAE = 1.2007
No improvement in validation loss for 5 epochs.
We are in epoch (training):  15
Epoch 15: Avg Train Loss = 2.4350
Epoch 15: Avg Train MAE = 1.1800
We are in epoch (val):  15
Epoch 15: Avg Val Loss = 2.6102
Epoch 15: Avg Val MAE = 1.1917
No improvement in validation loss for 6 epochs.
We are in epoch (training):  16
Epoch 16: Avg Train Loss = 2.3391
Epoch 16: Avg Train MAE = 1.1620
We are in epoch (val):  16
Epoch 16: Avg Val Loss = 2.5949
Epoch 16: Avg Val MAE = 1.1779
No improvement in validation loss for 7 epochs.
We are in epoch (training):  17
Epoch 17: Avg Train Loss = 1.9109
Epoch 17: Avg Train MAE = 1.0636
We are in epoch (val):  17
Epoch 17: Avg Val Loss = 2.7187
Epoch 17: Avg Val MAE = 1.1998
No improvement in validation loss for 8 epochs.
We are in epoch (training):  18
Epoch 18: Avg Train Loss = 1.8161
Epoch 18: Avg Train MAE = 1.0535
We are in epoch (val):  18
Epoch 18: Avg Val Loss = 2.7455
Epoch 18: Avg Val MAE = 1.1693
No improvement in validation loss for 9 epochs.
We are in epoch (training):  19
Epoch 19: Avg Train Loss = 1.6780
Epoch 19: Avg Train MAE = 1.0125
We are in epoch (val):  19
Epoch 19: Avg Val Loss = 2.8904
Epoch 19: Avg Val MAE = 1.1921
No improvement in validation loss for 10 epochs.
Early stopping triggered after 19 epochs.
Loaded the best model. Will now calculate predicted values on train and test set.
Loss plot (Train/Val) saved to: /mimer/NOBACKUP/groups/brainage/thesis_brainage/results/run_after_changes/loss_plot_trainval.png
We are in test.
Warning: No matching T1w image found for sub-OAS30643 in session(s). Skipping.
Warning: No matching T1w image found for sub-OAS30643 in session(s). Skipping.
Warning: No matching T1w image found for sub-OAS30643 in session(s). Skipping.
Warning: No matching T1w image found for sub-OAS30042 in session(s). Skipping.
Warning: No matching T1w image found for sub-OAS30797 in session(s). Skipping.
Warning: No matching T1w image found for sub-OAS30797 in session(s). Skipping.
Warning: No matching T1w image found for sub-OAS30797 in session(s). Skipping.
Loaded 443 image pairs.
Loaded 443 rows of metadata.
Loaded 443 targets.
We are in test
/mimer/NOBACKUP/groups/brainage/thesis_brainage/my_venv/lib/python3.12/site-packages/torchio/data/image.py:248: UserWarning: Using TorchIO images without a torchio.SubjectsLoader in PyTorch >= 2.3 might have unexpected consequences, e.g., the collated batches will be instances of torchio.Subject with 5D images. Replace your PyTorch DataLoader with a torchio.SubjectsLoader so that the collated batch becomes a dictionary, as expected. See https://github.com/TorchIO-project/torchio/issues/1179 for more context about this issue.
  warnings.warn(message, stacklevel=1)
/mimer/NOBACKUP/groups/brainage/thesis_brainage/scripts/new_run.py:340: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  
/mimer/NOBACKUP/groups/brainage/thesis_brainage/scripts/new_run.py:341: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  with torch.no_grad():
/mimer/NOBACKUP/groups/brainage/thesis_brainage/scripts/new_run.py:342: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  for batch in dataloader_test:
/mimer/NOBACKUP/groups/brainage/thesis_brainage/my_venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([16, 1, 1])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/mimer/NOBACKUP/groups/brainage/thesis_brainage/my_venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([11, 1, 1])) that is different to the input size (torch.Size([11, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
Test Loss (MSE): 15.4027
Test results saved to /mimer/NOBACKUP/groups/brainage/thesis_brainage/results/run_after_changes/test_predicted_values.csv
